{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOr6bQM8CAMSqZZaOYrisGX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alcarvalhox/alexandre/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyDwZ5vokfvi",
        "colab_type": "code",
        "outputId": "d83ddb97-9792-4684-d9cc-8eaa4f548c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.constraints import maxnorm\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Set random seed for purposes of reproducibility\n",
        "seed = 21\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# loading in the data\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# normalize the inputs from 0-255 to between 0 and 1 by dividing by 255\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "class_num = y_test.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(class_num))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "epochs = 25\n",
        "optimizer = 'adam'\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "numpy.random.seed(seed)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n",
        "\n",
        "# Model evaluation\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,264,458\n",
            "Trainable params: 2,263,114\n",
            "Non-trainable params: 1,344\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "50000/50000 [==============================] - 20s 395us/step - loss: 1.5030 - acc: 0.4655 - val_loss: 1.1685 - val_acc: 0.5775\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.0161 - acc: 0.6416 - val_loss: 0.8284 - val_acc: 0.7052\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 0.8483 - acc: 0.7008 - val_loss: 0.7673 - val_acc: 0.7260\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.7569 - acc: 0.7345 - val_loss: 0.7119 - val_acc: 0.7496\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.7046 - acc: 0.7513 - val_loss: 0.7030 - val_acc: 0.7544\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 0.6608 - acc: 0.7674 - val_loss: 0.7105 - val_acc: 0.7516\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6273 - acc: 0.7813 - val_loss: 0.6402 - val_acc: 0.7768\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.5976 - acc: 0.7897 - val_loss: 0.6077 - val_acc: 0.7882\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.5807 - acc: 0.7969 - val_loss: 0.7505 - val_acc: 0.7449\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 0.5571 - acc: 0.8053 - val_loss: 0.6303 - val_acc: 0.7837\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5354 - acc: 0.8117 - val_loss: 0.6024 - val_acc: 0.7912\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5288 - acc: 0.8140 - val_loss: 0.5540 - val_acc: 0.8102\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.5063 - acc: 0.8223 - val_loss: 0.5832 - val_acc: 0.7955\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4961 - acc: 0.8268 - val_loss: 0.5359 - val_acc: 0.8154\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.4873 - acc: 0.8293 - val_loss: 0.5515 - val_acc: 0.8107\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 0.4773 - acc: 0.8343 - val_loss: 0.6240 - val_acc: 0.7908\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 0.4690 - acc: 0.8354 - val_loss: 0.5367 - val_acc: 0.8156\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 0.4607 - acc: 0.8381 - val_loss: 0.5670 - val_acc: 0.8032\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 0.4558 - acc: 0.8406 - val_loss: 0.5411 - val_acc: 0.8151\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 0.4458 - acc: 0.8444 - val_loss: 0.5151 - val_acc: 0.8209\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 0.4412 - acc: 0.8446 - val_loss: 0.5800 - val_acc: 0.8054\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 0.4326 - acc: 0.8486 - val_loss: 0.5962 - val_acc: 0.7967\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 0.4289 - acc: 0.8500 - val_loss: 0.5091 - val_acc: 0.8257\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 0.4257 - acc: 0.8511 - val_loss: 0.5478 - val_acc: 0.8143\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 0.4206 - acc: 0.8524 - val_loss: 0.6052 - val_acc: 0.8016\n",
            "Accuracy: 80.16%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}